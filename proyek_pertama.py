# -*- coding: utf-8 -*-
"""Proyek Pertama.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GlKgMtcRlHpVUDMwbxE9jayZ8BOn7lSK

### **Stroke Prediction Model - Predictive Analytics**

**Import library**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""**Load Data**"""

data = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')
data.head(5)

"""Drop kolom atribut id data"""

data.drop('id', axis=1, inplace=True)
data.head()

"""**Exploratory Data Analytics (EDA)**

**Deskripsi Variabel**

mengecek informasi pada dataset dengan fungsi info()
"""

data.info()

"""mengecek deksripsi statistik data dengan fitur describe()"""

data.describe()

"""**Missing Value**

cek apakah ada data pada atribut yang bernilai null
"""

data.isnull().sum()

"""membuat box plot dengan kode berikut"""

fig = plt.subplots(figsize=(10, 6))
sns.boxplot(data=data, x='bmi')

"""dari box plot diatas, terdapat data outlier dan mana dapat mempengaruhi nilai mean, dengan begitu nilai null lebih cocok untuk diganti dengan nilai median"""

data['bmi'].fillna(data['bmi'].median(), inplace=True)
data.isna().sum()

"""**Univariate Analysis**

membagi dataset menjadi dua bagian, yaitu numerical dan categorical
"""

numerical_features = ['age', 'avg_glucose_level', 'bmi']
categorical_features = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']

"""Categorical Features

Fitur Gender
"""

feature = categorical_features[0]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Terdapat 3 kategori pada fitur gender, secara berurutan Female memiliki jumlah paling banyak.

Fitur Hypertension
"""

feature = categorical_features[1]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Pada grafik diatas bisa disimpulkan bahwa dari data lebih banyak grade pada pasien yang tidak memiliki tekanan darah

Fiture Heart_disease
"""

feature = categorical_features[2]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Pada grafik diatas bisa disimpulkan bahwa dari data lebih banyak grade pada pasien yang tidak memiliki penyakit jantung

Fitur ever_merried
"""

feature = categorical_features[3]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Pada grafik diatas bisa disimpulkan bahwa dari data lebih banyak grade pada pasien yang sudah menikah

Fitur work_type
"""

feature = categorical_features[4]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Pada grafik diatas bisa disimpulkan bahwa private memiliki grade tertinggi

Fitur Residence_type
"""

feature = categorical_features[5]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Pada grafik diatas bisa disimpulkan bahwa antar pasien yang tinggal di kota maupun pedesaan hampir memiliki grade yang sama

Fitur smoking status
"""

feature = categorical_features[6]
count = data[feature].value_counts()
percent = 100*data[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari grafik di tas, orang yang tidak pernah merokok memiliki grade tertinggi dan orang dengan status perokok memiliki grade yang rendah

**Data Preparation**

Melakukan encoding fitur dengan get_dummies. Pada tahap ini yaitu mengubah fitur kategori agar menjadi angka/numerik yang digunakan untuk untuk mendapatkan fitur baru yang sesuai sehingga dapat mewakili variabel kategori. Fitur tersebut adalah gender, ever_merried, work_type, Residence_type dan smoking status.
"""

from sklearn.preprocessing import  OneHotEncoder

data = pd.concat([data, pd.get_dummies(data['gender'], prefix='gender')],axis=1)
data = pd.concat([data, pd.get_dummies(data['ever_married'], prefix='ever_married')],axis=1)
data = pd.concat([data, pd.get_dummies(data['work_type'], prefix='work_type')],axis=1)
data = pd.concat([data, pd.get_dummies(data['Residence_type'], prefix='Residence_type')],axis=1)
data = pd.concat([data, pd.get_dummies(data['smoking_status'], prefix='smoking_status')],axis=1)
data.drop(['gender','ever_married','work_type', 'Residence_type', 'smoking_status'], axis=1, inplace=True)
data.head()

"""Reduksi dimensi dengan PCA"""

sns.pairplot(data[['age','bmi']], plot_kws={'s':2})

from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=123)
pca.fit(data[['age','bmi']])
princ_comp = pca.transform(data[['age','bmi']])

"""Kode di atas memanggil class PCA() dari library sciikit-learn. Paremeter yang kita masukkan ke dalam class adalah n_components dan random_state. Parameter n_components merupakan jumlah komponen atau dimensi, dalam kasus kita jumlahnya ada 2, yaitu 'age', dan 'bmi'. Pada parameter random_state kita menerapkan random_state = 123.

setelah menerapkan class PCA, kita bisa mengetahui proporsi informasi dari kedua komponen tadi
"""

pca.explained_variance_ratio_.round(3)

"""Arti dari output di atas adalah, 90.8% informasi pada ketiga fitur ‘age’, ‘bmi’ terdapat pada PC pertama. """

pca = PCA(n_components=1, random_state=123)
pca.fit(data[['age','bmi']])
data['fitur'] = pca.transform(data.loc[:, ('age','bmi')]).flatten()
data.drop(['age','bmi'], axis=1, inplace=True)

"""membagi data menjadi data train dan test dengan proporsi 80:20"""

from sklearn.model_selection import train_test_split
 
X = data.drop(["stroke"],axis =1)
y = data["stroke"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""Untuk menghindari kebocoran informasi pada data uji, kita hanya akan menerapkan fitur standarisasi pada data latih. Kemudian, pada tahap evaluasi, kita akan melakukan standarisasi pada data uji"""

from sklearn.preprocessing import StandardScaler

numerik = ['avg_glucose_level','fitur']
scaler = StandardScaler()
scaler.fit(X_train[numerik])
X_train[numerik] = scaler.transform(X_train.loc[:, numerik])
X_train[numerik].head()

"""Seperti yang telah disebutkan sebelumnya, proses standarisasi mengubah nilai rata-rata (mean) menjadi 0 dan nilai standar deviasi menjadi 1"""

X_train[numerik].describe().round(4)

"""dari tabel di atas, sekarang nilai mean = 0 dan standar deviasi = 1

**Modelling**
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""K-Nearest Neighbor

Pada model algoritama ini menggunakan k = 10 tetangga dan metric Euclidean untuk mengukur jarak antara titik
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
 
models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""Random Forest

Pada model algoritma ini terdapat beberapa parameter yang di isi dengan nilai :

*   n_estimators = 50 untuk jumlah trees (pohon) di forest
*   max_depth = 16 untuk membagi setiap node ke dalam jumlah pengamatan
*   random_state = 55 untuk mengontrol random number generator 
*   n_jobs = -1  untuk mengontrol thread atau proses yang berjalan secara paralel
"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor
 
# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""Boosting

Pada model algoritma ini terdapat beberapa parameter yang di isi dengan nilai :

*   learning_rate = 0.05 bobot yang diterapkan pada setiap regressor di masing-masing proses iterasi
*   random_state = 55 untuk mengontrol random number generator yang digunakan
"""

from sklearn.ensemble import AdaBoostRegressor
 
boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""**Evaluasi Model**

Pada potongan kode dibawah, Saat menghitung nilai Mean Squared Error pada data train dan test, kita membaginya dengan nilai 1e3. Hal ini bertujuan agar nilai mse berada dalam skala yang tidak terlalu besar
"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
# Panggil mse
mse

"""tabel di atas adalah hasil evaluasi pada data latih dan data test

plot metrik tersebut dengan bar chart
"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model K-Nearest Neighbor (KNN) memberikan nilai eror yang paling kecil. Sedangkan model dengan algoritma Boosting memiliki eror yang paling besar (berdasarkan grafik, angkanya di atas 8)"""